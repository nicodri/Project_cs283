\documentclass[11pt,a4paper,oneside]{report}

\usepackage{url, enumitem}
\usepackage{amsfonts, amsmath}
\usepackage{graphicx, color}
\usepackage{algorithm}
\usepackage[toc,page]{appendix}
\usepackage{lmodern}
\usepackage{natbib}

% Some useful macros.
\newcommand{\given}{\,|\,}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\var}{\text{var}}
\newcommand{\cov}{\text{cov}}

\usepackage{float}
\floatplacement{figure}{H} % force figures to be placed always at defined position!
\begin{document}

\title{CS 283: Initial Proposal}
\author{Nicolas Drizard \\
Leonhard Spiegelberg}
\date{10/23/15}

\maketitle

\newpage

\section*{Introduction}

Looking for an applied project, we decided to take part in a Kaggle competition: Right Whale Recognition! The objective of this competition is to build a program to recognize right whales in aerial photographies, given a training set with $500$ (North Atlantic) right whales. The dataset is constituted of $11,468$ aerial photographies with only one whale. Among these pictures, $4,545$ are already labeled with the ID of one of the $500$ whales. The main characteristics which help to differentiate one whale from another are the white callosities (roughened patches of skin) on their head.\\
\\

In this proposal, we first discuss some of the challenges of this problem and then present a potential roadmap to address this problem.


\section*{Challenges}

One of the main challenges with this problem relies in the feature engineering part. The images are raw pictures taken by a scientist with a normal camera and the whale is most of the time hard to recognize even with the naked eye. Different elements may perturb our work:
\begin{itemize}
	\item different lighting conditions need to addressed in the preprocessing step
	\item foam on the water has nearly the same color like the callosities we want to recognize. As foam takes nearly every shape, this will cause a lot of 'foam' features that will be incorrectly classified as callosities
	\item the orientation and position of the whale impacts visibility of the features, i.e. the whale can be half or more covered by water. Water refraction will change feature appearance.
\end{itemize}


\section*{Roadmap}
Given the lack of relevant information and the high level of noise in the pictures, we will use a progressive approach to solve this problem. \\
First, we will select a set of nice images (no distraction like foam, visible key features) to work on the feature engineering part to have a better understanding of the problem.\\
On these pictures, we will extract features. Two approaches may be considered. On the first hand, we extract a bag of features for each image (with SIFT for instance) and apply an algorithm to select the relevant features among them, i.e. the whale based one, and compare them (with a POOF approach for instance). On the other hand, we want to select directly the relevant features. Working on nice images makes this task easier as the noise is reduced. Then, we can apply the following classical feature extraction workflow:
\begin{enumerate}
	\item Preprocessing (i.e. normalizing luminance, converting channels, ...)
	\item Thresholding (extract pixels of interest, i.e. via a hysteresis approach)
   	\item Segmentation (Splitting the points into segments)
    	\item Feature estimation for each segment (i.e. half axes of ellipses, roundness measures, ...)
\end{enumerate}
Once we come up with relevant features, we run a classifier on the training set. We will focus on the feature engineering part so we will probably use a classical classifier as for instance SVM or regularized logistic regression. 

\section*{Implementation}
In order to classify a whale, we split the work in two parts. The first part consists of localizing the nose, its parts and extracting a feature vector from it for additional precision. The second part deals with the actual classification which shall be done using a part-based one-vs-one features (POOF) approach. 
\subsection*{Part I: Localizing the nose and parts of it}
As mentioned in the introduction callosities and the shape or size of a head are main features to distinguish a whale from the others. In order to localize the nose and parts of it, an approach using histograms of gradients as described in \citep{dalal2005histograms}
%\url{http://lear.inrialpes.fr/people/triggs/pubs/Dalal-cvpr05.pdf}
shall be implemented. Histograms of Oriented Gradients (HOG) is a method proposed by Dalal \& Triggs in 2005 which has been used previously to detect humans in images. 
\\
\\
The idea behind HOG is to describe a local object's shape and appearance via a histogram of (binned) gradients. To detect objects (in our case the whole nose and its parts (i.e. callosities)) a sliding window is used to feed the gradient histograms into a classifier. A first design choice that has to be made is what kind of window should be used. In general, two reasonable choices are rectangular or circular windows. As in the given dataset whales are arbitrarily oriented for a first analysis a squared window shall be used for the sake of simplicity and may be compared later to a circular version if performance needs to be increased.
\\
In general histograms can be fed into any classifier. In their paper Dalal \& Triggs use a support vector machine (SVM) to detect humans which shall be used as a first approach for the whale nose and its callosities.
\\
\\
As in many pictures callosities resemble foam features, it is not feasible to detect them with a sliding window over the whole original image. A better approach is to first use a larger sliding window to detect the actual nose part, extract a patch for it and perform then the HOG algorithm with a SVM again on this extracted patch to get callosity patches which can be fed into the POOF algorithm for whale classification.
\\
The callosity patches shall also be used to extract a feature vector (i.e. ellipses, roundness measures) that can be passed to POOF along the original patch.
\\
\\
To compute the gradient histograms as a first start VLFeat (\url{http://www.vlfeat.org/}) shall be used. For the SVM MATLAB's onboard implementation of the Statistics \& Machine Learning Toolbox shall be used as a starting point. To train the actual classifier first an adequate window size has to be determined in order to pass histograms to the classifier.

\subsection*{Part II: Part-based one-vs-one features}
<TODO>

\begin{appendices}
\chapter*{Whale Pictures}

\begin{figure}
	\centering
	\includegraphics[scale=0.1]{foam.jpg}
	\caption{Example of a whale aerial picture with foam}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[scale=0.15]{water.jpg}
	\caption{Example of a whale aerial picture with shining water}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[scale=0.1]{invisible.jpg}
	\caption{Example of a whale aerial picture where the callosities are not visible}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[scale=0.15]{better.jpg}
	\caption{Example of a relevant whale aerial picture}
\end{figure}

\end{appendices}

\bibliographystyle{unsrt}
\bibliography{bibliography.bib}

\end{document}
